{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.stem.porter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run', 'runner', 'running', 'ran', 'easily', 'fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run ---> run\n",
      "runner ---> runner\n",
      "running ---> run\n",
      "ran ---> ran\n",
      "easily ---> easili\n",
      "fairly ---> fairli\n"
     ]
    }
   ],
   "source": [
    "#Note how the stemmer recognizes \"runner\" as a noun, not a verb form or participle. Also, the adverbs \"easily\" and \"fairly\" are stemmed to the unusual root \"easili\" and \"fairli\"\n",
    "for word in words:\n",
    "    print(word+' ---> '+p_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "#The Snowball Stemmer requires that you pass a language parameter\n",
    "s_stemmer = SnowballStemmer(language='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = ['run','runner','running','ran','runs','easily','fairly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run ---> run\n",
      "runner ---> runner\n",
      "running ---> run\n",
      "ran ---> ran\n",
      "runs ---> run\n",
      "easily ---> easili\n",
      "fairly ---> fair\n"
     ]
    }
   ],
   "source": [
    "#In this case the stemmer performed the same as the Porter Stemmer, with the exception that it handled the stem of \"fairly\" more appropriately with \"fair\"\n",
    "\n",
    "for word in words:\n",
    "    print(word+' ---> '+s_stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I \t PRON \t 561228191312463089 \t 561228191312463089\n",
      "am \t AUX \t 10382539506755952630 \t 10382539506755952630\n",
      "a \t DET \t 11901859001352538922 \t 11901859001352538922\n",
      "runner \t NOUN \t 12640964157389618806 \t 12640964157389618806\n",
      "running \t VERB \t 12767647472892411841 \t 12767647472892411841\n",
      "in \t ADP \t 3002984154512732771 \t 3002984154512732771\n",
      "a \t DET \t 11901859001352538922 \t 11901859001352538922\n",
      "race \t NOUN \t 8048469955494714898 \t 8048469955494714898\n",
      "because \t SCONJ \t 16950148841647037698 \t 16950148841647037698\n",
      "I \t PRON \t 561228191312463089 \t 561228191312463089\n",
      "love \t VERB \t 3702023516439754181 \t 3702023516439754181\n",
      "to \t PART \t 3791531372978436496 \t 3791531372978436496\n",
      "run \t VERB \t 12767647472892411841 \t 12767647472892411841\n",
      "since \t SCONJ \t 10066841407251338481 \t 10066841407251338481\n",
      "I \t PRON \t 561228191312463089 \t 561228191312463089\n",
      "ran \t VERB \t 12767647472892411841 \t 12767647472892411841\n",
      "today \t NOUN \t 11042482332948150395 \t 11042482332948150395\n"
     ]
    }
   ],
   "source": [
    "doc1 = nlp(u\"I am a runner running in a race because I love to run since I ran today\")\n",
    "\n",
    "for token in doc1:\n",
    "    print(token.text, '\\t', token.pos_, '\\t', token.lemma, '\\t', token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In the above sentence, running, run and ran all point to the same lemma run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we're using an f-string to format the printed text by setting minimum field widths and adding a left-align to the lemma hash value.\n",
    "\n",
    "def show_lemmas(text):\n",
    "    for token in text:\n",
    "        print(f'{token.text:{12}} {token.pos_:{6}} {token.lemma:<{22}} {token.lemma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   561228191312463089     -PRON-\n",
      "saw          VERB   11925638236994514241   see\n",
      "eighteen     NUM    9609336664675087640    eighteen\n",
      "mice         NOUN   1384165645700560590    mouse\n",
      "today        NOUN   11042482332948150395   today\n",
      "!            PUNCT  17494803046312582752   !\n"
     ]
    }
   ],
   "source": [
    "doc2 = nlp(u\"I saw eighteen mice today!\")\n",
    "\n",
    "show_lemmas(doc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I            PRON   561228191312463089     -PRON-\n",
      "am           AUX    10382539506755952630   be\n",
      "meeting      VERB   6880656908171229526    meet\n",
      "him          PRON   561228191312463089     -PRON-\n",
      "tomorrow     NOUN   3573583789758258062    tomorrow\n",
      "at           ADP    11667289587015813222   at\n",
      "the          DET    7425985699627899538    the\n",
      "meeting      NOUN   14798207169164081740   meeting\n"
     ]
    }
   ],
   "source": [
    "doc3 = nlp(u\"I am meeting him tomorrow at the meeting\")\n",
    "\n",
    "show_lemmas(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That         DET    4380130941430378203    that\n",
      "'s           AUX    10382539506755952630   be\n",
      "an           DET    15099054000809333061   an\n",
      "enormous     ADJ    17917224542039855524   enormous\n",
      "automobile   NOUN   7211811266693931283    automobile\n"
     ]
    }
   ],
   "source": [
    "doc4 = nlp(u\"That's an enormous automobile\")\n",
    "\n",
    "show_lemmas(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'back', 'most', 'nothing', 'sometimes', 'namely', 'whoever', '‘s', 'anyway', 'several', 'seems', 'together', 'her', 'may', \"'ll\", 'him', 'keep', 'us', 'do', 'between', 'too', 'whereby', 'last', 'however', 'empty', 'is', 'thence', 'anyhow', 'ever', 'does', 'my', 'should', 'fifteen', 'thereby', '’m', 'even', 'full', 'per', 'onto', 'such', 'the', 'across', 'he', 'or', 'whole', 'though', 'they', 'until', 'quite', 'neither', 'whatever', 'nor', 'n’t', 'both', 'seem', 'as', 'could', 'go', 'became', 'hence', 'why', 'get', 'within', 'can', 'hundred', 'at', '’s', 'down', 'yours', 'that', 'over', '‘re', 'moreover', 'where', 'forty', 'besides', 'hereupon', 'somewhere', 'third', 'seemed', 'all', 'therein', 'six', 'no', 'twenty', 'whom', 'only', 'bottom', 'off', '‘ve', 'when', 'show', 'everywhere', 'which', 'yet', 'least', 'beforehand', '’ve', 'towards', 'due', 'some', 'wherever', 'fifty', 'mostly', 'below', 'whether', 're', 'was', 'less', 'thru', 'your', 'please', 'using', 'whose', 'more', 'either', 'because', 'did', 'every', 'something', 'perhaps', 'side', \"'m\", 'yourself', 'therefore', 'elsewhere', 'so', 'if', 'very', 'noone', 'never', 'during', 'move', 'above', 'without', \"'ve\", 'am', 'whereupon', 'herein', 'i', 'a', 'seeming', 'would', 'someone', 'through', 'by', 'before', 'been', 'being', 'beyond', 'although', 'throughout', 'whence', 'still', 'made', \"'d\", 'amongst', 'become', 'others', 'front', 'mine', 'might', 'whither', 'serious', 'cannot', 'myself', 'ten', 'those', 'be', 'against', 'around', 'also', 'under', 'thereafter', 'itself', 'to', 'another', 'eight', '‘ll', 'while', 'himself', 'alone', 'afterwards', 'done', 'beside', 'among', 'nine', 'meanwhile', 'upon', 'first', 'somehow', 'its', 'this', 'really', 'what', '’re', 'our', 'in', 'used', 'else', 'after', 'already', 'who', 'otherwise', 'take', 'becomes', 'are', 'than', 'here', 'it', 'we', 'via', 'then', 'you', 'she', 'his', 'up', 'whereafter', 'indeed', 'there', 'becoming', '‘d', 'have', \"n't\", 'own', 'hereby', 'rather', 'yourselves', 'one', 'say', 'since', 'many', 'an', 'part', 'ours', 'five', 'always', 'further', 'into', 'latterly', 'anywhere', 'nowhere', 'eleven', 'few', 'see', 'two', 'not', 'almost', 'except', 'ourselves', 'everything', 'make', 'toward', 'each', 'regarding', 'sometime', 'whenever', 'from', \"'s\", 'but', 'sixty', 'twelve', 'other', 'for', 'latter', 'hers', 'thereupon', 'wherein', 'call', 'again', 'nobody', 'unless', 'n‘t', 'former', 'themselves', 'none', 'enough', 'put', 'hereafter', 'much', 'about', 'out', 'name', 'with', 'me', 'next', 'has', 'will', 'often', 'anyone', 'and', 'various', 'any', 'whereas', 'them', '‘m', 'ca', 'had', 'now', 'same', 'their', \"'re\", 'nevertheless', 'of', '’ll', 'once', 'three', 'well', 'behind', 'anything', 'amount', 'top', 'herself', 'four', 'must', 'formerly', 'give', 'along', 'doing', 'were', 'how', 'on', 'thus', 'these', '’d', 'just', 'everyone'}\n"
     ]
    }
   ],
   "source": [
    "# Print the set of spaCy's default stop words (remember that sets are unordered):\n",
    "\n",
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['myself'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['mystery'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the word to the set of stop words. Use lowercase!\n",
    "\n",
    "nlp.Defaults.stop_words.add('btw')\n",
    "\n",
    "# Set the stop_word tag on the lexeme\n",
    "nlp.vocab['btw'].is_stop = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['btw'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the word from the set of stop words\n",
    "nlp.Defaults.stop_words.remove('beyond')\n",
    "\n",
    "# Remove the stop_word tag from the lexeme\n",
    "nlp.vocab['beyond'].is_stop = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "326"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab['beyond'].is_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
